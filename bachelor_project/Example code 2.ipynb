{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import HNL_newtry as HNL\n",
    "import pylhe\n",
    "\n",
    "events_mass_10 = list(pylhe.readLHE('HNL_M (10).lhe')) #contains 10^5 samples\n",
    "events_mass_20 = list(pylhe.readLHE('HNL_M (20).lhe'))\n",
    "events_mass_30 = list(pylhe.readLHE('HNL_M (30).lhe'))\n",
    "events_mass_40 = list(pylhe.readLHE('HNL_M (40).lhe')) \n",
    "events_mass_50 = list(pylhe.readLHE('HNL_M (50).lhe'))\n",
    "events_mass_60 = list(pylhe.readLHE('HNL_M (60).lhe'))\n",
    "events_mass_70 = list(pylhe.readLHE('HNL_M (70).lhe')) #contains 5*10^4 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_size = 5*10**4\n",
    "\n",
    "#Making first data set\n",
    "Data_params_1 = np.array(HNL.sort_data(events_mass_10,Sample_size))\n",
    "\n",
    "Learn_size = int(np.ceil(len(Data_params_1[0])))\n",
    "s_Data_params_1 =Data_params_1[:,0:Learn_size]\n",
    "\n",
    "Data_params_2 = np.array(HNL.sort_data(events_mass_20,Sample_size))\n",
    "s_Data_params_2 =Data_params_2[:,0:Learn_size]\n",
    "\n",
    "Data_params_3 = np.array(HNL.sort_data(events_mass_30,Sample_size))\n",
    "s_Data_params_3 =Data_params_3[:,0:Learn_size]\n",
    "\n",
    "Data_params_4 = np.array(HNL.sort_data(events_mass_40,Sample_size))\n",
    "s_Data_params_4 =Data_params_4[:,0:Learn_size]\n",
    "\n",
    "Data_params_5 = np.array(HNL.sort_data(events_mass_50,Sample_size))\n",
    "s_Data_params_5 =Data_params_5[:,0:Learn_size]\n",
    "\n",
    "Data_params_6 = np.array(HNL.sort_data(events_mass_60,Sample_size))\n",
    "s_Data_params_6 =Data_params_6[:,0:Learn_size]\n",
    "\n",
    "Data_params_7 = np.array(HNL.sort_data(events_mass_70,Sample_size))\n",
    "s_Data_params_7 =Data_params_7[:,0:Learn_size]\n",
    "\n",
    "#Combining them\n",
    "#s_data = s_Data_params_1.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = np.concatenate((s_Data_params_1.T,s_Data_params_2.T,s_Data_params_3.T,s_Data_params_4.T\\\n",
    "                         ,s_Data_params_5.T,s_Data_params_6.T,s_Data_params_7.T))\n",
    "\n",
    "p1 = np.array([s_data.T[0],s_data.T[1],s_data.T[2],s_data.T[3]])\n",
    "p2 = np.array([s_data.T[4],s_data.T[5],s_data.T[6],s_data.T[7]])\n",
    "q = np.array([s_data.T[8],s_data.T[9],s_data.T[10],s_data.T[11]])\n",
    "n = np.array([s_data.T[12],s_data.T[13],s_data.T[14],s_data.T[15]])\n",
    "m = s_data.T[16]\n",
    "mw = s_data.T[17]\n",
    "ppi = HNL.find_decay(p1,p2,q)[0]\n",
    "ptaun = HNL.find_decay(p1,p2,q)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trm(p1,p2):\n",
    "    ET1 = np.sqrt(p1[1]**2+p1[2]**2)\n",
    "    ET2 = np.sqrt(p2[1]**2+p2[2]**2)\n",
    "    return np.sqrt((ET1+ET2)**2-(p1[1]+p2[1])**2-(p1[2]+p2[2])**2)\n",
    "\n",
    "def prapid(p):\n",
    "    with np.errstate(divide='ignore'):\n",
    "        pAbs = np.sqrt(p[1]**2 + p[2]**2 + p[3]**2)\n",
    "        return np.arctanh(p[3] / pAbs)\n",
    "\n",
    "def make_set(p1,p2,q,n,N):\n",
    "    list = np.zeros([5,N])\n",
    "    E = p1[0]+p2[0]+q[0]\n",
    "    pT = (p1[1]+p2[1]+q[1])**2+(p1[2]+p2[2]+q[2])**2\n",
    "    nd = np.array([-p1[1],-p1[2],q[3]+p2[3]+n[3]])\n",
    "    nu = np.sqrt(nd[0]**2+nd[1]**2+nd[2]**2)\n",
    "    vn = np.array([-p1[1],-p1[2],p2[3]+q[3]+n[3]])/np.sqrt(p1[1]**2+p1[2]**2+(p2[3]+q[3]+n[3])**2)\n",
    "    pn = np.array([p2[1]+q[1],p2[2]+q[2],p2[3]+q[3]])   \n",
    "    cross = np.array([vn[2]*pn[1]-vn[1]*pn[2],vn[0]*pn[2]-vn[2]*pn[0],vn[1]*pn[0]-vn[0]*pn[1]])\n",
    "    q1 = np.sqrt(cross[0]**2+cross[1]**2+cross[2]**2)\n",
    "    q2 = pn[0]*vn[0]+pn[1]*vn[1]+pn[2]*vn[2] \n",
    "    pz = p1[1]*vn[0]+p1[2]*vn[1]+p1[3]*vn[2]\n",
    "    E1 = p1[0]\n",
    "    E2 = p2[0]+q[0]\n",
    "    B = (pz+q2)/(E1+E2)\n",
    "    mpt =np.array([0,-p1[1]-p2[1]-q[1],-p1[2]-p2[2]-q[2]])\n",
    "    nf = np.array([0,-p1[1]/nu,-p1[2]/nu,(q[3]+p2[3]+n[3])/nu])\n",
    "    y = HNL.find2(p1,p2,q,82)\n",
    "    \n",
    "    list[:][0] = y[0][1]/(p1[0]+p2[0]+q[0])\n",
    "    list[:][1] = y[1][1]/(p1[0]+p2[0]+q[0])\n",
    "    list[:][2] = (q[3]+p2[3]+y[0][0])/np.sqrt(p1[1]**2+p1[2]**2+(q[3]+p2[3]+y[0][0])**2)\n",
    "    list[:][3] = (q[3]+p2[3]+y[1][0])/np.sqrt(p1[1]**2+p1[2]**2+(q[3]+p2[3]+y[1][0])**2)\n",
    "    list[:][4] = (q[3]+p2[3]+n[3])/nu\n",
    "\n",
    "    return list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194070,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:,4].shape)\n",
    "\n",
    "for i in range(len(x_train[:,4])):\n",
    "    if np.isnan(x_train[i,3]) == True:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "set1 = np.array(make_set(p1,p2,q,n,len(p1[0]))).T\n",
    "\n",
    "x_train, x_test,y_train, y_test, E_train, E_test = train_test_split(set1,m/(p1[0]+p2[0]+q[0]),(p1[0]+p2[0]+q[0]),train_size = 0.8)\n",
    "\n",
    "#(1400,200)\n",
    "Model = MLPRegressor(hidden_layer_sizes=(1000),activation='relu',max_iter = 100,alpha =5.0e-06,verbose=True\\\n",
    "                     , learning_rate_init= 0.001, solver = 'adam',batch_size = 1000, random_state= 4,warm_start = True,tol = 10**(-8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.00361739\n",
      "Iteration 2, loss = 0.00039009\n",
      "Iteration 3, loss = 0.00031123\n",
      "Iteration 4, loss = 0.00027524\n",
      "Iteration 5, loss = 0.00025225\n",
      "Iteration 6, loss = 0.00023582\n",
      "Iteration 7, loss = 0.00022252\n",
      "Iteration 8, loss = 0.00021201\n",
      "Iteration 9, loss = 0.00020877\n",
      "Iteration 10, loss = 0.00020202\n",
      "Iteration 11, loss = 0.00019134\n",
      "Iteration 12, loss = 0.00018820\n",
      "Iteration 13, loss = 0.00018588\n",
      "Iteration 14, loss = 0.00018406\n",
      "Iteration 15, loss = 0.00018251\n",
      "Iteration 16, loss = 0.00017660\n",
      "Iteration 17, loss = 0.00017627\n",
      "Iteration 18, loss = 0.00017764\n",
      "Iteration 19, loss = 0.00017349\n",
      "Iteration 20, loss = 0.00017029\n",
      "Iteration 21, loss = 0.00017634\n",
      "Iteration 22, loss = 0.00016955\n",
      "Iteration 23, loss = 0.00016378\n",
      "Iteration 24, loss = 0.00016684\n",
      "Iteration 25, loss = 0.00016324\n",
      "Iteration 26, loss = 0.00016296\n",
      "Iteration 27, loss = 0.00015807\n",
      "Iteration 28, loss = 0.00015765\n",
      "Iteration 29, loss = 0.00016051\n",
      "Iteration 30, loss = 0.00016662\n",
      "Iteration 31, loss = 0.00015797\n",
      "Iteration 32, loss = 0.00015004\n",
      "Iteration 33, loss = 0.00015176\n",
      "Iteration 34, loss = 0.00015414\n",
      "Iteration 35, loss = 0.00015480\n",
      "Iteration 36, loss = 0.00015199\n",
      "Iteration 37, loss = 0.00014889\n",
      "Iteration 38, loss = 0.00014497\n",
      "Iteration 39, loss = 0.00014938\n",
      "Iteration 40, loss = 0.00014568\n",
      "Iteration 41, loss = 0.00014381\n",
      "Iteration 42, loss = 0.00014656\n",
      "Iteration 43, loss = 0.00014583\n",
      "Iteration 44, loss = 0.00014143\n",
      "Iteration 45, loss = 0.00014339\n",
      "Iteration 46, loss = 0.00014063\n",
      "Iteration 47, loss = 0.00014400\n",
      "Iteration 48, loss = 0.00013716\n",
      "Iteration 49, loss = 0.00013952\n",
      "Iteration 50, loss = 0.00014275\n",
      "Iteration 51, loss = 0.00014084\n",
      "Iteration 52, loss = 0.00014059\n",
      "Iteration 53, loss = 0.00013578\n",
      "Iteration 54, loss = 0.00013541\n",
      "Iteration 55, loss = 0.00013305\n",
      "Iteration 56, loss = 0.00013881\n",
      "Iteration 57, loss = 0.00018234\n",
      "Iteration 58, loss = 0.00014253\n",
      "Iteration 59, loss = 0.00013565\n",
      "Iteration 60, loss = 0.00013980\n",
      "Iteration 61, loss = 0.00013335\n",
      "Iteration 62, loss = 0.00013442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rasat\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=5e-06, batch_size=1000, beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=1000, learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=4, shuffle=True, solver='adam',\n",
       "             tol=1e-08, validation_fraction=0.1, verbose=True, warm_start=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Model.predict(x_test)*E_test,bins=100)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
